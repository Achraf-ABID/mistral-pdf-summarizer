# üìù G√©n√©rateur de R√©sum√©s et QCM avec Mistral 7B

Ce projet fournit un pipeline complet pour analyser des documents PDF, en extraire les informations cl√©s, et g√©n√©rer automatiquement des r√©sum√©s concis ainsi que des questionnaires √† choix multiples (QCM) pertinents.

Il s'appuie sur le mod√®le de langage de pointe **Mistral 7B** et une architecture de **G√©n√©ration Augment√©e par R√©cup√©ration (RAG)** pour garantir des r√©sultats de haute qualit√©, m√™me sur des documents longs et complexes.

## ‚ú® Fonctionnalit√©s

-   **Extraction de Texte depuis PDF** : G√®re un ou plusieurs fichiers PDF en entr√©e.
-   **G√©n√©ration de R√©sum√©s** : Cr√©e des r√©sum√©s clairs, structur√©s et multilingues (Fran√ßais, Anglais).
-   **G√©n√©ration de QCM** : Produit des questionnaires pertinents avec 4 options de r√©ponse pour √©valuer la compr√©hension.
-   **Analyse S√©mantique** : Utilise des embeddings et une base de donn√©es vectorielle (FAISS) pour trouver les passages les plus pertinents avant la g√©n√©ration.
-   **Mod√®le Optimis√©** : Profite de la puissance de Mistral-7B-Instruct, optimis√© avec la quantification 4-bits pour s'ex√©cuter sur des GPU avec des ressources limit√©es.

## üèõÔ∏è Architecture du projet (RAG)

Le syst√®me suit une approche de G√©n√©ration Augment√©e par R√©cup√©ration (RAG) pour fournir des r√©ponses contextuellement riches et pr√©cises.

1.  **Chargement et D√©coupage** : Le texte est d'abord extrait des fichiers PDF. Il est ensuite d√©coup√© en plus petits segments (chunks) pour √™tre plus facilement traitable par les mod√®les.
2.  **Cr√©ation d'Embeddings** : Chaque segment de texte est transform√© en une repr√©sentation num√©rique (vecteur d'embedding) √† l'aide du mod√®le `BAAI/bge-small-en-v1.5`. Ces vecteurs capturent le sens s√©mantique du texte.
3.  **Indexation (FAISS)** : Les vecteurs sont stock√©s et index√©s dans une base de donn√©es vectorielle FAISS. Cet index permet une recherche de similarit√© ultra-rapide.
4.  **R√©cup√©ration (Retrieval)** : Lorsqu'une requ√™te est faite (par exemple, "g√©n√®re un r√©sum√©"), le syst√®me recherche dans l'index FAISS les segments de texte les plus pertinents s√©mantiquement.
5.  **G√©n√©ration (Mistral 7B)** : Les segments pertinents r√©cup√©r√©s sont inject√©s dans un prompt structur√© et envoy√©s au mod√®le Mistral 7B. Le mod√®le utilise ce contexte pour g√©n√©rer un r√©sum√© ou un QCM pr√©cis et fid√®le au document source.

## üõ†Ô∏è Technologies Utilis√©es

-   **Mod√®le LLM** : `mistralai/Mistral-7B-Instruct-v0.1`
-   **Mod√®le d'Embedding** : `BAAI/bge-small-en-v1.5`
-   **Frameworks IA/ML** : `Hugging Face Transformers`, `PyTorch`, `LangChain` (pour le d√©coupage de texte)
-   **Base de Donn√©es Vectorielle** : `FAISS (Facebook AI Similarity Search)`
-   **Traitement de PDF** : `PyMuPDF (fitz)`
-   **Optimisation** : `bitsandbytes` (pour la quantification 4-bits)

## üöÄ D√©marrage Rapide

### 1. Pr√©requis

-   Python 3.8+
-   Un environnement avec GPU est fortement recommand√© (NVIDIA T4, V100, A100...).
-   Un compte Hugging Face et un token d'acc√®s.

### 2. Installation

Clonez ce d√©p√¥t et installez les d√©pendances :

```bash
# Cloner le projet (exemple)
git clone https://votre-url-de-projet.git
cd votre-projet

# Installer les packages requis
pip install -U torch torchvision torchaudio
pip install -q -U transformers accelerate sentence-transformers langchain faiss-cpu pymupdf bitsandbytes huggingface_hub
